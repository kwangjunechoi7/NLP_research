{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7391205490454961"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sin(1/10000**(1/dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- transformer는 recurrence도 아니고 convolution도 아니기 때문에, 단어의 sequence를 이용하기 위해서는 단어의 position에 대한 정보를 추가할 필요가 있음. 그래서 endcoder와 decoder의 input embedding에 positionla encoding을 더해줌. \n",
    "\n",
    "\n",
    "- positional encoding은 <em><string>d</string></em><sub>model</sub>(embedding의 차원)과 같은 차원을 갖기 때문에 positional encoding vector와 embedding vector는 더해질 수 있음\n",
    "\n",
    "\n",
    "- 논문에서는 다른 frequency(주어진 구간 내에서 완료되는 cycle 횟수)를 가지고 sin과 cos 함수를 이용함 "
   ]
  },
  {
   "attachments": {
    "image.png": {"image.png": "./positional_encoding.png"}
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pos는 position, i 는 dimention이고 주기가 10000<sup>2i/dmodel</sup> * 2π인 삼각함수임.\n",
    "- 즉 pos는 sequence에서 단어의 위치이고, 해당 단어는 i에 0부터 d<sup>model</sup> / 2까지를 대입해 d<sup>model</sup> 차원의 positional encoding vector를 얻게 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding1(sentence_length, dim):\n",
    "    encoded_vec = []\n",
    "    for pos in range(sentence_length):\n",
    "        for i in range(dim):\n",
    "            vec = pos/10000**(2*i/dim)\n",
    "            \n",
    "            if i%2 == 0:\n",
    "                vec = np.sin(vec)\n",
    "            else:\n",
    "                vec = np.cos(vec)\n",
    "            encoded_vec.append(vec)\n",
    "    return np.array(encoded_vec).reshape([sentence_length, dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = positional_encoding1(10, 20)\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [8.41470985e-01, 9.21796446e-01, 1.57826640e-01, 9.98010124e-01,\n",
       "        2.51162229e-02, 9.99950000e-01, 3.98106119e-03, 9.99998744e-01,\n",
       "        6.30957303e-04, 9.99999968e-01, 9.99999998e-05, 9.99999999e-01,\n",
       "        1.58489319e-05, 1.00000000e+00, 2.51188643e-06, 1.00000000e+00,\n",
       "        3.98107171e-07, 1.00000000e+00, 6.30957344e-08, 1.00000000e+00],\n",
       "       [9.09297427e-01, 6.99417376e-01, 3.11697146e-01, 9.92048417e-01,\n",
       "        5.02165994e-02, 9.99800007e-01, 7.96205928e-03, 9.99994976e-01,\n",
       "        1.26191435e-03, 9.99999874e-01, 1.99999999e-04, 9.99999997e-01,\n",
       "        3.16978638e-05, 1.00000000e+00, 5.02377286e-06, 1.00000000e+00,\n",
       "        7.96214341e-07, 1.00000000e+00, 1.26191469e-07, 1.00000000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple하게 표현 \n",
    "def positional_encoding2(sentence_length, dim):\n",
    "    encoded_vec = np.array([pos/10000**(2*i/dim) for pos in range(sentence_length) for i in range(dim)])\n",
    "    encoded_vec[::2] = np.sin(encoded_vec[::2])\n",
    "    encoded_vec[1::2] = np.cos(encoded_vec[1::2])\n",
    "    return np.array(encoded_vec).reshape([sentence_length, dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = positional_encoding2(10, 20)\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [8.41470985e-01, 9.21796446e-01, 1.57826640e-01, 9.98010124e-01,\n",
       "        2.51162229e-02, 9.99950000e-01, 3.98106119e-03, 9.99998744e-01,\n",
       "        6.30957303e-04, 9.99999968e-01, 9.99999998e-05, 9.99999999e-01,\n",
       "        1.58489319e-05, 1.00000000e+00, 2.51188643e-06, 1.00000000e+00,\n",
       "        3.98107171e-07, 1.00000000e+00, 6.30957344e-08, 1.00000000e+00],\n",
       "       [9.09297427e-01, 6.99417376e-01, 3.11697146e-01, 9.92048417e-01,\n",
       "        5.02165994e-02, 9.99800007e-01, 7.96205928e-03, 9.99994976e-01,\n",
       "        1.26191435e-03, 9.99999874e-01, 1.99999999e-04, 9.99999997e-01,\n",
       "        3.16978638e-05, 1.00000000e+00, 5.02377286e-06, 1.00000000e+00,\n",
       "        7.96214341e-07, 1.00000000e+00, 1.26191469e-07, 1.00000000e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [8.41470985e-01, 9.50415280e-01, 9.98334166e-02, 9.99500042e-01,\n",
       "        9.99983333e-03, 9.99995000e-01, 9.99999833e-04, 9.99999950e-01,\n",
       "        9.99999998e-05, 9.99999999e-01, 1.00000000e-05, 1.00000000e+00,\n",
       "        1.00000000e-06, 1.00000000e+00, 1.00000000e-07, 1.00000000e+00,\n",
       "        1.00000000e-08, 1.00000000e+00, 1.00000000e-09, 1.00000000e+00],\n",
       "       [9.09297427e-01, 8.06578410e-01, 1.98669331e-01, 9.98000667e-01,\n",
       "        1.99986667e-02, 9.99980000e-01, 1.99999867e-03, 9.99999800e-01,\n",
       "        1.99999999e-04, 9.99999998e-01, 2.00000000e-05, 1.00000000e+00,\n",
       "        2.00000000e-06, 1.00000000e+00, 2.00000000e-07, 1.00000000e+00,\n",
       "        2.00000000e-08, 1.00000000e+00, 2.00000000e-09, 1.00000000e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_length = 10\n",
    "dim = 20\n",
    "\n",
    "encoded_vec = np.array([pos/100000**(2*i/dim) for pos in range(sentence_length) for i in range(dim)])\n",
    "\n",
    "encoded_vec[::2] = np.sin(encoded_vec[::2])\n",
    "encoded_vec[1::2] = np.cos(encoded_vec[1::2])\n",
    "\n",
    "encoded_vec.reshape([sentence_length, dim])[:3]\n",
    "#using convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
