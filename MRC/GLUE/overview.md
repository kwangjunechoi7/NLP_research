### GLUE dataset 이해하기

- Chris McCormick과 Nick Ryan이 공동으로 작성한 GLUE explained:Understading BERT through benchmark 출처

- GLUE(general language understanding evaluation) 벤치마크는 강건하고 범용적인 자연어 이해 시스템의 개발이라는 목적을 가지고 제작된 데이터 셋.
- 자연어 처리 모델을 훈련시키고, 그 성능을 평가 및 비교 분석하기 위한 데이터셋들로 구성되어있음. 다양하고 해결하기 어려운 9개의 태스크 데이터셋으로 구성된 GLUE는 모델들의 자연어 이해 능력을 평가하기 위해 고안되었으며, 이제는 BERT와 같은 전이학습 모델들을 평가하기 위한 필수적인 벤치마크가 됨.

- 자연처 처리 태스크?
	+ named entity recognition : 문장 내 특정 단어가 고유 명사, 기관명 혹은 entity인가?
	+ textual entailment : 두 문장이 주어졌을 때, 첫 번째 문장이 두 번째 문장을 수반하는가 혹은 위배되는가?
	+ Coreference Resolution : 문장 내 대명사 it이 존재하고 해당 대명사가 지칭할 수 있는 명사가 많을 때, it 이 지칭하는 정확한 대상은?

- 대부분은 특정 태스크의 해결에만 관심을 갖기 떄문에 모델이 coreference resolution에 어떤 성능을 보이는지에 대해서는 관심을 갖지 않음

- 그러나 모든 자연어 처리 task들은 언어적인 측면에서 서로 연결되어있다는 점을 이해하는 것이 중요

- 만약 사용자가 리뷰에 대한 감정 분석에만 관심이 있더라도 문장 내 대명사가 가리키는 바가 무엇인지를 잘 아는 모델들은 즉 coreference resolution을 해결할 수 있는 모델들은 기뷰 내 모호한 명사들에 대해서도 효과적인 판단이 가능. 이러한 이유 때문에 bert와 같은 transfer-learning model들이 GLUE Benchmark와 같이 다양한 자연어 처리 태스크에서 좋은 성능을 보인다는 것은 해당 모델들이 여러 특정 task에서도 효과적이라는 반증이 됨.

- 과거 자연어 처리 모델들은 거의 대부분 하나의 특정한 문제를 잘 처리하기 위해 설계되었기 떄문에 end-to-end로 해당 문제를 푸는데에만 적합하게 훈련됨 그래서 다른 데이터셋에 대해서 효과적이지 못했음

- 특정 문제만을 해결하기 위해 end-to-end로 학습된 single task model들과 달리, transfer-learning모델들은 deep 한 모델을 이용해 자연어의 일반화된 이해를 중점으로 학습함

- 즉 pre-train으로 언어에 대한 일반적인 이해능력을 갖게 된 것.

- 이처럼 pre-train을 통해 얻어진 자연어 이해 능력은 해당 모델을 특정 태스크에 수행하기 위해 fine-tuning 할 때 그 빛을 발하게 됨. 프로세스는 다음과 같음
	+ 사전 학습에 사용되었던 입력층과 출력층을 기존 모델에서 제거
	+ 입력층과 츨력층을 해결하고자 하는 문제에 적합한 층으로 교체
	+ 위 과정을 거쳐 변형된 모델을 n번 동안 재학습(fine-tuning)
	+ 이 때, 사전학습 모델에서 차용한 모델의 중간부는 자연어를 잘 ‘이해’하는 parameter를 지니고 있기 때문에 우리가 풀고자하는 문제 해결에 큰 도움을 줌

- 그렇다면, 새 모델이 이전 모델들보다 더 좋은 성능을 내는지 어떻게 평가할까? 라는 아이디어에서 출발. 모델의 일반적인 언어 ‘이해’능력과 더불어 fine-tuning을 통해 특정 태스크에 얼마나 좋은 성능을 낼 수 있는지 평가하고 싶기 때문
